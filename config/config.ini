# Divergent Inference Analysis Configuration

[model]
# Model settings

model_name = Qwen/Qwen3-1.7B

# device to run model on - options are 'cpu' or 'cuda'
device = cuda


[generation]
# Stem Generation parameters
seed = 42

# cumulative token entropy limit for each generated stem
entropy_budget = 11

# cumulative token entropy limit for all nodes along a path
max_entropy_depth = 15

# max token length of each stem
stem_length = 8

# number of stems to generate and attempt to cluster at each node
num_stems = 256

# number of stems to generate per forward pass - larger batch sizes may be faster, but will also consume more memory
batch_size = 64

# Token-level filtering
# increasing temperature creates more diverse stems, and may require a greater num_stems
# value to generate a sufficient amount for effective cluster formation
temperature = 1.0
top_k = 0
top_p = 1.0

# maximum gap between cluster proportions: .10 = clusters with (.10 * num_stems) fewer members than the next largest cluster, will be excluded
max_proportion_gap = 0.15

[embeddings]
# General embedding parameters

# Embedding model for semantic analysis
model_name = sentence-transformers/all-MiniLM-L12-v2

# number of embeddings to generate per forward pass
batch_size = 256

# Apply L2 normalization to embeddings before/after delta calculation
normalize_pre_delta = True
normalize_post_delta = True

# custom pooling method for embeddings - options are 'mean', 'max', 'lasttoken', 'weighted'
custom_pooling = lasttoken


[clustering]
# Semantic clustering parameters
cluster_type = hierarchical

# min_sample_ratio is the smallest allowable ratio of a cluster's size,
# in proportion to the total samples generated for a node. It functions as a fallback for
# cases where clustering produces many small clusters
min_sample_ratio = 0.02

# linkage criterion to use - options are 'average', 'complete', 'single', 'ward', 'weighted'
linkage_criterion = weighted

# less distance creates more clusters with greater semantic similarity and fewer members
cut_distance = 0.52

# hierarchical clusters are sorted by their sample count and pulled from the top until
# the total number of pulled samples is at least cluster_top_p * total_samples
# This is to prevent the algorithm from returning hundreds of small clusters
# TODO: consider implementing this as a UI slider that dynamically redraws the tree
#       we're already generating the clusters; might as well preserve the option to look at them
cluster_top_p = 0.5

# force return the largest cluster even if it doesn't meet the min_sample_ratio
# if false, nodes with 0 child clusters will simply terminate
force_cluster = false

[visualization]
# Visualization settings

template_path = templates/tree_template.html
output_dir = ./output/renders

# Type of PCA normalization to apply to positions after PCA reduction
# current options are 'unit_sphere' or 'none'
pca_normalization = none


[analysis]
# Analysis report parameters
output_dir = ./output/reports
